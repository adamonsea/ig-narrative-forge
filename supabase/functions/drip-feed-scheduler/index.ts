import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.192.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.7.1';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface DripFeedTopic {
  id: string;
  name: string;
  drip_feed_enabled: boolean;
  drip_release_interval_hours: number;
  drip_stories_per_release: number;
  drip_start_hour: number;
  drip_end_hour: number;
}

interface ReadyStory {
  id: string;
  title: string;
  scheduled_publish_at: string | null;
  drip_queued_at: string | null;
  topic_article_id: string | null;
  article_id: string | null;
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  const startTime = Date.now();
  const logs: string[] = [];
  const log = (msg: string) => {
    const entry = `[${new Date().toISOString()}] ${msg}`;
    logs.push(entry);
    console.log(entry);
  };

  try {
    const supabaseUrl = Deno.env.get('SUPABASE_URL');
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
    
    if (!supabaseUrl || !supabaseKey) {
      throw new Error('Missing required environment variables');
    }

    const supabase = createClient(supabaseUrl, supabaseKey);
    
    // Parse request body for optional topic_id filter
    let targetTopicId: string | null = null;
    let emergencyPublishAll = false;
    try {
      const body = await req.json();
      targetTopicId = body.topic_id || null;
      emergencyPublishAll = body.emergency_publish_all === true;
    } catch {
      // No body or invalid JSON - that's fine
    }

    log('üïê Drip Feed Scheduler starting...');

    // Emergency publish all - bypass drip feed for a topic
    if (emergencyPublishAll && targetTopicId) {
      log(`üö® EMERGENCY: Publishing all ready stories for topic ${targetTopicId}`);
      
      // Get all ready stories for this topic with scheduled times
      const { data: emergencyStories, error: emergencyError } = await supabase
        .from('stories')
        .select('id, title, topic_article_id')
        .eq('status', 'ready')
        .not('scheduled_publish_at', 'is', null);

      if (emergencyError) {
        throw new Error(`Failed to fetch emergency stories: ${emergencyError.message}`);
      }

      // Filter to only stories from this topic
      const topicStoryIds: string[] = [];
      for (const story of emergencyStories || []) {
        if (story.topic_article_id) {
          const { data: ta } = await supabase
            .from('topic_articles')
            .select('topic_id')
            .eq('id', story.topic_article_id)
            .single();
          
          if (ta?.topic_id === targetTopicId) {
            topicStoryIds.push(story.id);
          }
        }
      }

      if (topicStoryIds.length > 0) {
        // Clear scheduled_publish_at to allow immediate publishing
        const { error: clearError } = await supabase
          .from('stories')
          .update({ scheduled_publish_at: null })
          .in('id', topicStoryIds);

        if (clearError) {
          throw new Error(`Failed to clear scheduled times: ${clearError.message}`);
        }

        log(`‚úÖ Cleared scheduled times for ${topicStoryIds.length} stories - they will publish immediately`);
      }

      // Log the emergency action
      await supabase.from('system_logs').insert({
        level: 'warn',
        function_name: 'drip-feed-scheduler',
        message: `Emergency publish all triggered for topic`,
        context: { 
          topic_id: targetTopicId, 
          stories_released: topicStoryIds.length,
          triggered_at: new Date().toISOString()
        }
      });

      return new Response(
        JSON.stringify({
          success: true,
          emergency: true,
          stories_released: topicStoryIds.length,
          message: `Released ${topicStoryIds.length} stories for immediate publishing`
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Get topics with drip feed enabled
    const topicQuery = supabase
      .from('topics')
      .select('id, name, drip_feed_enabled, drip_release_interval_hours, drip_stories_per_release, drip_start_hour, drip_end_hour')
      .eq('drip_feed_enabled', true)
      .eq('is_active', true);

    if (targetTopicId) {
      topicQuery.eq('id', targetTopicId);
    }

    const { data: topics, error: topicsError } = await topicQuery;

    if (topicsError) {
      throw new Error(`Failed to fetch topics: ${topicsError.message}`);
    }

    if (!topics || topics.length === 0) {
      log('No topics with drip feed enabled');
      return new Response(
        JSON.stringify({ success: true, message: 'No drip feed topics found', logs }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    log(`Found ${topics.length} topic(s) with drip feed enabled`);

    const now = new Date();
    const currentHour = now.getUTCHours();
    const results: Array<{ topic: string; scheduled: number; skipped: string }> = [];

    for (const topic of topics as DripFeedTopic[]) {
      log(`\nüì∞ Processing topic: ${topic.name}`);
      
      // Check if we're within release hours
      const startHour = topic.drip_start_hour ?? 6;
      const endHour = topic.drip_end_hour ?? 22;
      
      const withinReleaseWindow = currentHour >= startHour && currentHour < endHour;
      
      if (!withinReleaseWindow) {
        log(`‚è∞ Outside release window (${startHour}:00 - ${endHour}:00 UTC), current: ${currentHour}:00`);
        results.push({ topic: topic.name, scheduled: 0, skipped: 'outside_release_window' });
        continue;
      }

      // Get ready stories for this topic that don't have scheduled_publish_at set
      const { data: readyStories, error: storiesError } = await supabase
        .from('stories')
        .select(`
          id, 
          title, 
          scheduled_publish_at,
          drip_queued_at,
          topic_article_id,
          article_id
        `)
        .eq('status', 'ready')
        .is('scheduled_publish_at', null)
        .order('created_at', { ascending: true });

      if (storiesError) {
        log(`‚ùå Error fetching stories: ${storiesError.message}`);
        continue;
      }

      // Filter stories to only those belonging to this topic
      const topicStories: ReadyStory[] = [];
      
      for (const story of readyStories || []) {
        if (story.topic_article_id) {
          // Multi-tenant architecture
          const { data: topicArticle } = await supabase
            .from('topic_articles')
            .select('topic_id')
            .eq('id', story.topic_article_id)
            .single();
          
          if (topicArticle?.topic_id === topic.id) {
            topicStories.push(story as ReadyStory);
          }
        } else if (story.article_id) {
          // Legacy architecture
          const { data: article } = await supabase
            .from('articles')
            .select('topic_id')
            .eq('id', story.article_id)
            .single();
          
          if (article?.topic_id === topic.id) {
            topicStories.push(story as ReadyStory);
          }
        }
      }

      if (topicStories.length === 0) {
        log(`No unscheduled ready stories for ${topic.name}`);
        results.push({ topic: topic.name, scheduled: 0, skipped: 'no_stories' });
        continue;
      }

      log(`Found ${topicStories.length} unscheduled ready stories`);

      // Calculate release slots for today
      const intervalHours = topic.drip_release_interval_hours ?? 4;
      const storiesPerRelease = topic.drip_stories_per_release ?? 2;
      
      // Find the next available slot by checking already scheduled stories
      const { data: existingScheduled } = await supabase
        .from('stories')
        .select('scheduled_publish_at')
        .eq('status', 'ready')
        .not('scheduled_publish_at', 'is', null)
        .gte('scheduled_publish_at', now.toISOString());
      
      // Count stories per existing time slot
      const slotCounts = new Map<string, number>();
      for (const s of existingScheduled || []) {
        // Check if this story belongs to current topic (need to verify)
        const timeKey = s.scheduled_publish_at;
        slotCounts.set(timeKey, (slotCounts.get(timeKey) || 0) + 1);
      }
      
      // Calculate remaining slots today
      const hoursRemaining = endHour - currentHour;
      const slotsRemaining = Math.ceil(hoursRemaining / intervalHours);
      
      log(`Scheduling up to ${storiesPerRelease} stories per slot, ${intervalHours}h intervals, ${slotsRemaining} slots remaining today`);

      let scheduledCount = 0;
      
      // Calculate first available slot time (next interval boundary from now)
      const firstSlotTime = new Date(now);
      firstSlotTime.setUTCMinutes(0, 0, 0);
      // Round up to next interval
      const currentSlotHour = Math.ceil((currentHour + 1) / intervalHours) * intervalHours;
      firstSlotTime.setUTCHours(currentSlotHour > endHour ? startHour : currentSlotHour);
      
      // If we've passed today's window, schedule for tomorrow
      if (currentSlotHour > endHour) {
        firstSlotTime.setUTCDate(firstSlotTime.getUTCDate() + 1);
      }

      let currentSlotTime = new Date(firstSlotTime);
      let storiesInCurrentSlot = 0;

      for (const story of topicStories) {
        // Check if current slot is within release window
        const slotHour = currentSlotTime.getUTCHours();
        if (slotHour >= endHour) {
          log(`‚è∞ Reached end of release window (${endHour}:00), stopping scheduling`);
          break;
        }
        
        // Check how many stories already exist in this slot
        const slotKey = currentSlotTime.toISOString();
        const existingInSlot = slotCounts.get(slotKey) || 0;
        
        // If slot is full, move to next slot
        if (storiesInCurrentSlot + existingInSlot >= storiesPerRelease) {
          currentSlotTime.setUTCHours(currentSlotTime.getUTCHours() + intervalHours);
          storiesInCurrentSlot = 0;
          
          // Re-check window after advancing
          if (currentSlotTime.getUTCHours() >= endHour) {
            log(`‚è∞ Next slot would be outside release window, stopping`);
            break;
          }
        }

        const { error: updateError } = await supabase
          .from('stories')
          .update({ 
            scheduled_publish_at: currentSlotTime.toISOString(),
            drip_queued_at: now.toISOString()
          })
          .eq('id', story.id);

        if (updateError) {
          log(`‚ùå Failed to schedule story ${story.id}: ${updateError.message}`);
          continue;
        }

        // Log each scheduled story to database
        await supabase.rpc('log_drip_feed_event', {
          p_topic_id: topic.id,
          p_event_type: 'story_scheduled',
          p_story_id: story.id,
          p_details: {
            title: story.title,
            scheduled_for: currentSlotTime.toISOString(),
            stories_in_slot: storiesInCurrentSlot + 1
          }
        });

        log(`üìÖ Scheduled "${story.title?.substring(0, 40)}..." for ${currentSlotTime.toISOString()} (slot has ${storiesInCurrentSlot + 1}/${storiesPerRelease})`);
        scheduledCount++;
        storiesInCurrentSlot++;
      }

      results.push({ topic: topic.name, scheduled: scheduledCount, skipped: '' });
      log(`‚úÖ Scheduled ${scheduledCount} stories for ${topic.name}`);
    }

    // Calculate totals for summary
    const totalScheduled = results.reduce((sum, r) => sum + r.scheduled, 0);
    const topicsProcessed = results.filter(r => r.scheduled > 0).length;
    const topicsSkipped = results.filter(r => r.skipped).length;

    // Log detailed summary to system_logs
    await supabase.from('system_logs').insert({
      level: 'info',
      function_name: 'drip-feed-scheduler',
      message: `Drip feed scheduler completed: ${totalScheduled} stories scheduled across ${topicsProcessed} topics`,
      context: { 
        results,
        summary: {
          total_stories_scheduled: totalScheduled,
          topics_processed: topicsProcessed,
          topics_skipped: topicsSkipped,
          trigger_source: targetTopicId ? 'story_ready_trigger' : 'cron_job'
        },
        duration_ms: Date.now() - startTime,
        current_hour_utc: currentHour,
        run_timestamp: new Date().toISOString()
      }
    });

    log(`\nüìä Summary: ${totalScheduled} stories scheduled, ${topicsProcessed} topics processed, ${topicsSkipped} skipped`);

    log(`\n‚úÖ Drip Feed Scheduler completed in ${Date.now() - startTime}ms`);

    return new Response(
      JSON.stringify({
        success: true,
        results,
        duration_ms: Date.now() - startTime,
        logs
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    log(`‚ùå Fatal error: ${errorMessage}`);
    
    return new Response(
      JSON.stringify({ 
        success: false, 
        error: errorMessage,
        logs 
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );
  }
});
